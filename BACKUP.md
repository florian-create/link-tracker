# üîê Syst√®me de Backup Automatique

Ce guide explique comment configurer et utiliser le syst√®me de backup automatique pour sauvegarder les donn√©es du Link Tracker vers Google Drive.

## üìã Vue d'ensemble

Le syst√®me de backup exporte quotidiennement :
- ‚úÖ Table `links` (tous les liens cr√©√©s)
- ‚úÖ Table `clicks` (tous les clics avec informations enrichies)

Les backups sont au format **CSV** et upload√©s automatiquement sur **Google Drive**.

## üöÄ Configuration initiale

### √âtape 1 : Cr√©er un compte de service Google

1. Allez sur [Google Cloud Console](https://console.cloud.google.com/)
2. Cr√©ez un nouveau projet ou s√©lectionnez un projet existant
3. Activez l'API Google Drive :
   - Menu ‚Üí "APIs & Services" ‚Üí "Library"
   - Cherchez "Google Drive API"
   - Cliquez sur "Enable"

4. Cr√©ez un compte de service :
   - Menu ‚Üí "APIs & Services" ‚Üí "Credentials"
   - Cliquez sur "Create Credentials" ‚Üí "Service Account"
   - Donnez un nom : `link-tracker-backup`
   - Cliquez sur "Create and Continue"
   - Role : "Editor" (ou cr√©ez un r√¥le personnalis√©)
   - Cliquez sur "Done"

5. Cr√©ez une cl√© JSON :
   - Cliquez sur le compte de service cr√©√©
   - Onglet "Keys"
   - "Add Key" ‚Üí "Create new key"
   - Type : **JSON**
   - T√©l√©chargez le fichier JSON

### √âtape 2 : Configurer Google Drive

1. Cr√©ez un dossier d√©di√© dans Google Drive pour les backups
   - Exemple : `Link Tracker Backups`

2. Partagez ce dossier avec le compte de service :
   - Clic droit sur le dossier ‚Üí "Partager"
   - Collez l'email du compte de service (format: `xxx@xxx.iam.gserviceaccount.com`)
   - Donnez les droits "√âditeur"
   - Cliquez sur "Partager"

3. R√©cup√©rez l'ID du dossier :
   - Ouvrez le dossier dans Google Drive
   - L'URL ressemble √† : `https://drive.google.com/drive/folders/XXXXX`
   - L'ID est la partie `XXXXX` apr√®s `/folders/`

### √âtape 3 : Configuration des variables d'environnement

#### Sur Render.com :

1. Allez dans votre service Render
2. Onglet "Environment"
3. Ajoutez ces variables :

```bash
GOOGLE_SERVICE_ACCOUNT_JSON=/etc/secrets/service-account.json
GOOGLE_DRIVE_FOLDER_ID=votre_folder_id_google_drive
```

4. Ajoutez le fichier JSON comme "Secret File" :
   - Dans "Environment" ‚Üí "Secret Files"
   - Filename: `/etc/secrets/service-account.json`
   - Contents: Collez le contenu du fichier JSON t√©l√©charg√©

#### En local (d√©veloppement) :

Cr√©ez un fichier `.env` :

```bash
DATABASE_URL=postgresql://localhost/link_tracker
GOOGLE_SERVICE_ACCOUNT_JSON=./service-account.json
GOOGLE_DRIVE_FOLDER_ID=votre_folder_id_google_drive
```

Placez votre fichier `service-account.json` √† la racine du projet.

‚ö†Ô∏è **IMPORTANT** : Ajoutez ces fichiers au `.gitignore` :
```
.env
service-account.json
```

## üìÖ Configuration du backup quotidien

### Option 1 : Cron Job (Render.com)

Render supporte les cron jobs natifs. Modifiez `render.yaml` :

```yaml
services:
  # Service web existant
  - type: web
    name: link-tracker
    env: python
    buildCommand: "pip install -r requirements.txt"
    startCommand: "gunicorn app:app"
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: link-tracker-db
          property: connectionString

  # Nouveau cron job pour backup
  - type: cron
    name: link-tracker-backup
    env: python
    schedule: "0 2 * * *"  # Tous les jours √† 2h du matin (UTC)
    buildCommand: "pip install -r requirements.txt"
    startCommand: "python backup_to_drive.py"
    envVars:
      - key: DATABASE_URL
        fromDatabase:
          name: link-tracker-db
          property: connectionString
      - key: GOOGLE_SERVICE_ACCOUNT_JSON
        sync: false
      - key: GOOGLE_DRIVE_FOLDER_ID
        sync: false
```

### Option 2 : GitHub Actions

Cr√©ez `.github/workflows/backup.yml` :

```yaml
name: Daily Database Backup

on:
  schedule:
    - cron: '0 2 * * *'  # Tous les jours √† 2h du matin (UTC)
  workflow_dispatch:  # Permet de lancer manuellement

jobs:
  backup:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Create service account file
        run: |
          echo '${{ secrets.GOOGLE_SERVICE_ACCOUNT_JSON }}' > service-account.json

      - name: Run backup
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          GOOGLE_SERVICE_ACCOUNT_JSON: ./service-account.json
          GOOGLE_DRIVE_FOLDER_ID: ${{ secrets.GOOGLE_DRIVE_FOLDER_ID }}
        run: |
          python backup_to_drive.py
```

Ajoutez ces secrets dans GitHub :
- `DATABASE_URL`
- `GOOGLE_SERVICE_ACCOUNT_JSON`
- `GOOGLE_DRIVE_FOLDER_ID`

### Option 3 : Service externe (EasyCron, cron-job.org)

Cr√©ez un endpoint API dans `app.py` :

```python
@app.route('/api/backup', methods=['POST'])
def trigger_backup():
    """Endpoint pour d√©clencher un backup (prot√©g√© par cl√© API)"""
    api_key = request.headers.get('X-API-Key')

    # V√©rifier la cl√© API
    if api_key != os.environ.get('BACKUP_API_KEY'):
        return jsonify({'error': 'Unauthorized'}), 401

    try:
        # Lancer le backup en arri√®re-plan
        import subprocess
        subprocess.Popen(['python', 'backup_to_drive.py'])
        return jsonify({'success': True, 'message': 'Backup started'}), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500
```

Puis configurez un cron externe pour appeler cet endpoint.

## üß™ Test du backup manuel

### En local :

```bash
# Installer les d√©pendances
pip install -r requirements.txt

# Configurer les variables d'environnement
export DATABASE_URL="postgresql://localhost/link_tracker"
export GOOGLE_SERVICE_ACCOUNT_JSON="./service-account.json"
export GOOGLE_DRIVE_FOLDER_ID="votre_folder_id"

# Lancer le backup
python backup_to_drive.py
```

### Sur Render :

Vous pouvez d√©clencher manuellement le cron job depuis le dashboard Render :
1. Allez dans votre service cron
2. Cliquez sur "Trigger Run"

## üìä Format des fichiers de backup

### `links_backup_YYYYMMDD_HHMMSS.csv`

Colonnes :
- `id` : ID interne
- `link_id` : ID court du lien
- `first_name`, `last_name`, `email` : Informations prospect
- `icp` : Profil client id√©al
- `campaign` : Nom de la campagne
- `destination_url` : URL de destination
- `created_at` : Date de cr√©ation

### `clicks_backup_YYYYMMDD_HHMMSS.csv`

Colonnes :
- `id` : ID du clic
- `link_id` : ID du lien cliqu√©
- `clicked_at` : Date/heure du clic
- `ip_address` : Adresse IP
- `user_agent` : User agent du navigateur
- `country`, `city` : G√©olocalisation
- `referer` : Page d'origine
- `first_name`, `last_name`, `email`, `campaign`, `icp` : Infos du prospect

## üîÑ Restauration depuis un backup

### Restaurer la table `links` :

```bash
# Se connecter √† PostgreSQL
psql $DATABASE_URL

# Cr√©er une table temporaire
CREATE TABLE links_restore (LIKE links);

# Copier les donn√©es depuis le CSV
\copy links_restore FROM 'links_backup.csv' WITH CSV HEADER;

# V√©rifier les donn√©es
SELECT COUNT(*) FROM links_restore;

# Restaurer (ATTENTION : Cela √©crase les donn√©es existantes !)
TRUNCATE links CASCADE;  -- CASCADE supprime aussi les clicks !
INSERT INTO links SELECT * FROM links_restore;

# Nettoyer
DROP TABLE links_restore;
```

### Restaurer la table `clicks` :

```bash
# Cr√©er une table temporaire
CREATE TABLE clicks_restore (
    id SERIAL PRIMARY KEY,
    link_id VARCHAR(10),
    clicked_at TIMESTAMP,
    ip_address VARCHAR(45),
    user_agent TEXT,
    country VARCHAR(100),
    city VARCHAR(100),
    referer TEXT
);

# Copier les donn√©es (uniquement les colonnes de la table clicks)
\copy clicks_restore(id, link_id, clicked_at, ip_address, user_agent, country, city, referer) FROM 'clicks_backup.csv' WITH CSV HEADER;

# V√©rifier
SELECT COUNT(*) FROM clicks_restore;

# Restaurer
TRUNCATE clicks;
INSERT INTO clicks SELECT * FROM clicks_restore;

# Nettoyer
DROP TABLE clicks_restore;
```

## üîç V√©rification des backups

### V√©rifier dans Google Drive :

1. Ouvrez le dossier de backup
2. Vous devriez voir 2 fichiers par jour :
   - `links_backup_20250115_020000.csv`
   - `clicks_backup_20250115_020000.csv`

### Script de v√©rification automatique :

```python
# verify_backups.py
from google.oauth2 import service_account
from googleapiclient.discovery import build

credentials = service_account.Credentials.from_service_account_file(
    'service-account.json',
    scopes=['https://www.googleapis.com/auth/drive.readonly']
)

service = build('drive', 'v3', credentials=credentials)

# Lister les fichiers du dossier
results = service.files().list(
    q=f"'{FOLDER_ID}' in parents",
    orderBy='createdTime desc',
    fields='files(name, createdTime, size)'
).execute()

for file in results.get('files', []):
    print(f"{file['name']} - {file['createdTime']} - {file['size']} bytes")
```

## üìà Monitoring et alertes

### Option 1 : Logs Render

Les logs du cron job sont disponibles dans Render Dashboard ‚Üí Logs

### Option 2 : Alertes par email

Modifiez `backup_to_drive.py` pour envoyer des emails en cas d'erreur :

```python
import smtplib
from email.mime.text import MIMEText

def send_alert(subject, message):
    """Envoyer une alerte email en cas d'erreur"""
    msg = MIMEText(message)
    msg['Subject'] = subject
    msg['From'] = os.environ.get('ALERT_EMAIL_FROM')
    msg['To'] = os.environ.get('ALERT_EMAIL_TO')

    with smtplib.SMTP(os.environ.get('SMTP_SERVER'), 587) as server:
        server.starttls()
        server.login(os.environ.get('SMTP_USER'), os.environ.get('SMTP_PASS'))
        server.send_message(msg)

# Dans la fonction backup_database()
if not backup_successful:
    send_alert(
        "‚ùå Link Tracker Backup Failed",
        f"Backup failed on {datetime.now()}\nCheck logs for details."
    )
```

## üîí S√©curit√©

- ‚úÖ Ne jamais committer le fichier `service-account.json`
- ‚úÖ Utiliser des variables d'environnement pour les secrets
- ‚úÖ Limiter les permissions du compte de service (acc√®s Drive uniquement)
- ‚úÖ Chiffrer les backups si donn√©es sensibles (RGPD)
- ‚úÖ D√©finir une politique de r√©tention (ex: garder 30 jours)

## üí° Conseils

1. **Testez r√©guli√®rement la restauration** : Un backup non test√© n'est pas un vrai backup !
2. **Gardez plusieurs versions** : Configurez la r√©tention √† 30 jours minimum
3. **Surveillez l'espace Drive** : Les backups peuvent prendre de la place
4. **Documentez les proc√©dures** : En cas de catastrophe, pas le temps de chercher
5. **Backup hors-ligne** : T√©l√©chargez occasionnellement des copies locales

## üÜò Troubleshooting

### Erreur : "Service account file not found"

‚úÖ V√©rifiez que `GOOGLE_SERVICE_ACCOUNT_JSON` pointe vers le bon fichier

### Erreur : "Insufficient Permission"

‚úÖ V√©rifiez que le dossier Drive est partag√© avec le compte de service
‚úÖ V√©rifiez que l'API Drive est activ√©e

### Erreur : "No data found"

‚úÖ Normal si la base de donn√©es est vide
‚úÖ Le script cr√©era quand m√™me un fichier vide

### Le cron ne se lance pas

‚úÖ V√©rifiez le format du cron : `0 2 * * *`
‚úÖ V√©rifiez les logs du service
‚úÖ Testez manuellement le script

## üìû Support

Pour toute question ou probl√®me :
1. Consultez les logs du backup
2. V√©rifiez les permissions Google Drive
3. Testez le script manuellement en local

---

**Derni√®re mise √† jour** : 2025-01-15
